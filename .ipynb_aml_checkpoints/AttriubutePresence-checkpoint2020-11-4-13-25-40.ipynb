{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.5)\r\n",
            "Requirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2020.10.28)\r\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (7.1.2)\r\n",
            "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\r\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.51.0)\r\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import ast\r\n",
        "from nltk.tokenize import WhitespaceTokenizer\r\n",
        "import random"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113567993
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving the different Dataset stored in csv files\r\n",
        "\r\n",
        "usernames_df = pd.read_csv(\"../mitchall.boesel/Twitter/tweets.csv\", names=[\"Data\", \"Label\"], header=0)\r\n",
        "hostnames_df = pd.read_csv(\"../caesar.white/hostnames_strings.csv\", names=[\"Data\", \"Label\"], header=0)\r\n",
        "filenames_df = pd.read_csv(\"../jongyun.kim/featuriaztion/filenames.csv\", names=[\"Data\", \"Label\"], header=0)\r\n",
        "ip_df = pd.read_csv(\"../cougsInAzure/IP_Datapoints.csv\", names=[\"Data\", \"Label\"], header=0)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113570674
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the datasets into positive and negative lists\r\n",
        "def IsPositive(r):\r\n",
        "    return True if r[1] else False\r\n",
        "def IsNegative(r):\r\n",
        "    return True if not r[1] else False\r\n",
        "\r\n",
        "username_list = usernames_df.values.tolist()\r\n",
        "hostnames_list = hostnames_df.values.tolist()\r\n",
        "filenames_list = filenames_df.values.tolist()\r\n",
        "ip_list = ip_df.values.tolist()\r\n",
        "\r\n",
        "positive_dataset = list(filter(IsPositive, username_list+hostnames_list+filenames_list+ip_list))\r\n",
        "negative_dataset = list(filter(IsNegative, username_list+hostnames_list+filenames_list+ip_list))\r\n",
        "\r\n",
        "random.shuffle(positive_dataset)\r\n",
        "random.shuffle(negative_dataset)\r\n",
        "\r\n",
        "print(len(positive_dataset))\r\n",
        "print(positive_dataset[:10])\r\n",
        "print(len(negative_dataset))\r\n",
        "print(negative_dataset[:10])\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28366\n",
            "[['RT Anthony_Chiang: Hours after agreeing to richest contract in Heat history, Bam Adebayo stood in Charles Hadley Park and helped deliver m', 1], ['RT hughriminton: A man I know, with two Masters degrees and a background in academia and finance, is unemployed. He points out #MathiasCor', 1], [':ate night halo come hang outhttps://t.co/lJpiRHjShP3Betrayals#btryl https://t.co/OvAa0vxBvA', 1], ['/images/web/2009/banner.png', 1], ['groucho-norcal', 1], ['RT theweeknd: The Grammys remain corrupt. You owe me, my fans and the industry transparency...', 1], ['Spotify taylorswift13 helpianaaaahttps://t.co/NgMmm789D3', 1], ['groucho-sa', 1], ['RT ValentinoKhan: WOW ... !  already 1 milli on Anything and counting on SpotifyThanks for all the love yall awonderland https://t.co/', 1], ['RT DigiSliceX: Samsungs Galaxy Z Flip 2 launch is reportedly delayed until after the first quarter of 2021 (Sponsored by GadgetDealPro)', 1]]\n",
            "12610\n",
            "[['You can now use CSP Azure subscription for CMG with ConfigMgr 2010 that just released. (The feature is still pre-release. #memcm #ConfigMgrhttps://t.co/vw3kzB1m16', 0], ['Stateful vs Stateless Firewall: Which Option Is Best for Your Business - BizTech Magazine: https://t.co/NoDl2OPPsf #follow &amp; #RT #cybersecurity #infosec', 0], ['Request sent at 2013-03-09 21:12:52', 0], ['Packet received at 2013-06-03 01:27:49', 0], ['Braves picked up a great rotation piece#AtlantaBraves #Braves #MLB #MLBShowdown #MLBTeamBuilder https://t.co/j2z2pOTF21', 0], ['Client port number 24259', 0], ['One time #Respectfully  my son Justin always wallen for no reason  https://t.co/qzHG77RkOt', 0], ['32 students from Year 7, 9 students from Year 9, 1 student from Year 10, and 2 students from Year 11 achieved 5 or more awards over the past fortnight. Well done to all of those students!', 0], ['Request sent at 2013-04-15 23:17:21', 0], ['3HERSHEL-GUY', 0]]\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113573092
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the dataset into 1\r\n",
        "dataset = []\r\n",
        "l = len(negative_dataset) if len(negative_dataset) < len(positive_dataset) else len(positive_dataset)\r\n",
        "\r\n",
        "for i in range(0,l):\r\n",
        "    dataset.append(positive_dataset[i])\r\n",
        "    dataset.append(negative_dataset[i])\r\n",
        "print(dataset[:5])\r\n",
        "print(len(dataset))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['RT Anthony_Chiang: Hours after agreeing to richest contract in Heat history, Bam Adebayo stood in Charles Hadley Park and helped deliver m', 1], ['You can now use CSP Azure subscription for CMG with ConfigMgr 2010 that just released. (The feature is still pre-release. #memcm #ConfigMgrhttps://t.co/vw3kzB1m16', 0], ['RT hughriminton: A man I know, with two Masters degrees and a background in academia and finance, is unemployed. He points out #MathiasCor', 1], ['Stateful vs Stateless Firewall: Which Option Is Best for Your Business - BizTech Magazine: https://t.co/NoDl2OPPsf #follow &amp; #RT #cybersecurity #infosec', 0], [':ate night halo come hang outhttps://t.co/lJpiRHjShP3Betrayals#btryl https://t.co/OvAa0vxBvA', 1]]\n",
            "25220\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113578844
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\r\n",
        "\r\n",
        "# Username specific features\r\n",
        "def LowerUnderscoreUpper(s):\r\n",
        "    l = len(s)\r\n",
        "\r\n",
        "    for i in range(0,l-2):\r\n",
        "        if s[i].islower() and s[i+1] == '_' and s[i+2].isupper():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasUnderscore(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for c in s:\r\n",
        "        if c == '_':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def LowerUpperLower(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for i in range(0, len(s)-2):\r\n",
        "        if s[i].islower() and s[i+1].isupper() and s[i+2].islower():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def MultipleLowerUpperLower(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    flag = False\r\n",
        "    for i in range(0, len(s)-2):\r\n",
        "        if s[i].islower() and s[i+1].isupper() and s[i+2].islower():\r\n",
        "            if flag:\r\n",
        "                return True\r\n",
        "            else:\r\n",
        "                flag = True\r\n",
        "    return False\r\n",
        "\r\n",
        "def ExactlyTwoUppercase(s):\r\n",
        "    count = 0\r\n",
        "\r\n",
        "    for c in s:\r\n",
        "        if c.isupper():\r\n",
        "            count+=1\r\n",
        "    if count ==2:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def AllLowerMoreThan(bound, s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    if len(s) < bound:\r\n",
        "        return False\r\n",
        "    for c in s:\r\n",
        "        if c.isupper():\r\n",
        "            return False\r\n",
        "    return True\r\n",
        "\r\n",
        "def AdjacentUppers(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for i in range(0,len(s)-1):\r\n",
        "        if s[i].isupper() and s[i+1].isupper():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def StartLetterEndNonLetter(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    if s[0].isalpha() and not s[-1].isalpha():\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "\r\n",
        "# Hostname specific features\r\n",
        "def LengthGTLT(gt, ls, s):\r\n",
        "    l = len(str(s))\r\n",
        "    if l >= gt and l <= ls:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def IllegalHostnameChars(s):\r\n",
        "    s = str(s)\r\n",
        "    illegal_chars = [\".\", \"\\\", \"\"/\", \"*\", \"?\", \"\\\"\", \"<\", \">\", \"|\", \",\", \"~\", \":\", \"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"'\", \"(\", \")\", \"{\", \"}\", \" \"]\r\n",
        "    for c in s:\r\n",
        "        if c in illegal_chars:\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def AlphaOrDigit(s):\r\n",
        "    s = str(s)\r\n",
        "    if s.isalpha() or s.isdigit():\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HostIllegalEnding(s):\r\n",
        "    s = str(s)\r\n",
        "    if s[-1] == '-' or s[-1] == '.':\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "# Filename specific features\r\n",
        "\r\n",
        "def ContainsPeriod(s):\r\n",
        "    s = str(s)\r\n",
        "    for c in s:\r\n",
        "        if c == '.':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def IsUrl(s):\r\n",
        "    s = str(s)\r\n",
        "    l = len(s)\r\n",
        "    if l > 3:\r\n",
        "        if s[0:4] == \"http\":\r\n",
        "            return True\r\n",
        "    if l > 4:\r\n",
        "        if s[0:5] == \"https\":\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasSlash(s):\r\n",
        "    s = str(s)\r\n",
        "    for c in s:\r\n",
        "        if c == '/' or c == '\\\\':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasMultipleSlash(s):\r\n",
        "    s = str(s)\r\n",
        "    slashes = ['/','\\\\']\r\n",
        "    flag = False\r\n",
        "    for c in s:\r\n",
        "        if not flag and c in slashes:\r\n",
        "            flag = True\r\n",
        "        elif flag and c in slashes:\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasPossibleExtension(s):\r\n",
        "    s = str(s)\r\n",
        "    for i in range(0,len(s)):\r\n",
        "        if s[i] == '.':\r\n",
        "            x = s[i:-1]\r\n",
        "            if len(x) >= 2 and len(x) <= 4:\r\n",
        "                return True\r\n",
        "    return False\r\n",
        "\r\n",
        "# IP Features\r\n",
        "def NumbersThenPeriod(s):\r\n",
        "    s = str(s)\r\n",
        "    freq = 0\r\n",
        "    for i in range(0,len(s)-1):\r\n",
        "        if s[i] >= '0' and s[i] <= '9' and s[i+1] == '.':\r\n",
        "            freq += 1\r\n",
        "    return True if freq == 3 else False"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116491568
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features and labels\r\n",
        "feature_list = []\r\n",
        "labels = []\r\n",
        " \r\n",
        "tk = WhitespaceTokenizer() \r\n",
        "\r\n",
        "for dp in dataset:\r\n",
        "    d = dp[0]\r\n",
        "    label = dp[1]\r\n",
        "    tokens = tk.tokenize(d)\r\n",
        "    tokens = list(filter(lambda x: not IsUrl(x), tokens))\r\n",
        "    dp_list = []\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LowerUnderscoreUpper(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasUnderscore(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LowerUpperLower(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: MultipleLowerUpperLower(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: ExactlyTwoUppercase(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AllLowerMoreThan(10,x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AdjacentUppers(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: StartLetterEndNonLetter(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LengthGTLT(1, 15, x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: IllegalHostnameChars(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AlphaOrDigit(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HostIllegalEnding(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: ContainsPeriod(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasSlash(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasMultipleSlash(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasPossibleExtension(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: NumbersThenPeriod(x), tokens)) else dp_list.append(False)\r\n",
        "    feature_list.append(dp_list)\r\n",
        "    labels.append(label)\r\n"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116500100
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN MACHINE LEARNING MODELS\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113601917
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcAccuracy(target, predictions):\r\n",
        "    total = len(predictions)\r\n",
        "    correct = 0\r\n",
        "    for i in range(len(predictions)):\r\n",
        "        if target[i] == predictions[i]:\r\n",
        "            correct += 1\r\n",
        "        accuracy = float(correct) / float(total)\r\n",
        "    return accuracy\r\n",
        "\r\n",
        "def FalsePositives(x_test, y_test, pred):\r\n",
        "    false_positives = []\r\n",
        "    for i in range(0, len(x_test)):\r\n",
        "        if y_test[i] == 0 and pred[i] == 1:\r\n",
        "            false_positives.append(x_test[i])\r\n",
        "    return false_positives\r\n",
        "\r\n",
        "def FalseNegatives(x_test, y_test, pred):\r\n",
        "    false_negatives = []\r\n",
        "    for i in range(0,len(x_test)):\r\n",
        "        if y_test[i] == 1 and pred[i] == 0:\r\n",
        "            false_negatives.append(x_test[i])\r\n",
        "    return false_negatives\r\n",
        "\r\n",
        "def PrintResults(classifier, acc, recall, precision):\r\n",
        "    print(classifier + \" Classifier\")\r\n",
        "    print(\"Accuracy= \", acc)\r\n",
        "    print(\"Precision= \", precision)\r\n",
        "    print(\"Recall= \", recall)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607113604927
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = feature_list # all the features\r\n",
        "y = labels     # labels, 1 or 0\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\r\n",
        "print(len(X))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25220\n"
          ]
        }
      ],
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116504416
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DECISION TREE CLASSIFIER\r\n",
        "dt = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "pred = dt.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Decision Tree\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy=  0.9301934398654331\n",
            "Precision=  0.9308191208263271\n",
            "Recall=  0.9297024952015355\n",
            "\n",
            "FP-> 288 \n",
            "FN-> 293\n"
          ]
        }
      ],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116507344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN CLASSIFIER\r\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\r\n",
        "knn.fit(X_train, y_train)\r\n",
        "pred = knn.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"KNN\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier\n",
            "Accuracy=  0.9275501622011294\n",
            "Precision=  0.9277657787377009\n",
            "Recall=  0.9275431861804223\n",
            "\n",
            "FP-> 301 \n",
            "FN-> 302\n"
          ]
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116516377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION CLASSIFER\r\n",
        "lr = LogisticRegression(random_state=0)\r\n",
        "lr.fit(X_train, y_train)\r\n",
        "pred = lr.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Logistic Regression\", acc, recall, precision)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier\n",
            "Accuracy=  0.8952300853057792\n",
            "Precision=  0.9095427435387674\n",
            "Recall=  0.8781190019193857\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116520532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FORREST\r\n",
        "rfm = RandomForestClassifier().fit(X_train, y_train)\r\n",
        "pred = rfm.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Random Forrest\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forrest Classifier\n",
            "Accuracy=  0.9311546317433618\n",
            "Precision=  0.9319875030040855\n",
            "Recall=  0.9304222648752399\n",
            "\n",
            "FP-> 283 \n",
            "FN-> 290\n"
          ]
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116524126
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NAIVE BAYS\r\n",
        "nb = GaussianNB().fit(X_train, y_train)\r\n",
        "pred = nb.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Naive Bays\", acc, recall, precision)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bays Classifier\n",
            "Accuracy=  0.7509311546317433\n",
            "Precision=  0.8796665458499456\n",
            "Recall=  0.5822936660268714\n"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1607116530162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try/Catch for recognizing if input is json or not\r\n",
        "\r\n",
        "#data_dict = list(map(lambda x : ast.literal_eval(x), data))\r\n",
        "for x in dataset[:5]:\r\n",
        "    print(x)\r\n",
        "\r\n",
        "for y in dataset:\r\n",
        "    x = None\r\n",
        "    try:\r\n",
        "        x = ast.literal_eval(y[0])\r\n",
        "        #print(f\"It didn't break! {x}\")\r\n",
        "    except (ValueError, SyntaxError):\r\n",
        "        z = True\r\n",
        "        #print(f\"It broke:( {y}\") \r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#ReTweetThis for #OurMischief #BBlogRT SGH_RTs GFXCoach FearRTs ShoutGamers Demented_RTs Mighty_RTs DynoRTs NightRetweets WitWGARA posted: https://t.co/oAcPcjMyvAWatch Ninja now streaming VALORANTat https://t.co/QghgQSwvrL- #ThankYou for being #OurMischief! Wit', 1]\n",
            "['TRUDYDELEON-', 0]\n",
            "['groucho-eu', 1]\n",
            "['7JERRY-NELSON', 0]\n",
            "['RT tkasasagi: My Kuzushiji recognition mobile app using Tensorflow and Flutter project got awarded research grant from Japan Science and T', 1]\n"
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606874741766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = WhitespaceTokenizer() \r\n",
        "t1 = \"Hello\"\r\n",
        "token = tk.tokenize(t1)\r\n",
        "print(token)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello']\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606874783950
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}