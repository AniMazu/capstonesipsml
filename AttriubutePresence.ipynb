{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.5)\r\n",
            "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.51.0)\r\n",
            "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (7.1.2)\r\n",
            "Requirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2020.10.28)\r\n",
            "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\r\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import ast\r\n",
        "from nltk.tokenize import WhitespaceTokenizer\r\n",
        "import random"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606800785804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving the different Dataset stored in csv files\r\n",
        "\r\n",
        "usernames_df = pd.read_csv(\"../mitchall.boesel/Twitter/tweets.csv\", names=[\"Data\", \"Label\"], header=0)\r\n",
        "hostnames_df = pd.read_csv(\"../caesar.white/hostnames_strings.csv\", names=[\"Data\", \"Label\"], header=0)\r\n",
        "filenames_df = pd.read_csv(\"../jongyun.kim/featuriaztion/filenames.csv\", names=[\"Data\", \"Labels\"], header=0)"
      ],
      "outputs": [],
      "execution_count": 73,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876577821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the datasets into positive and negative lists\r\n",
        "def IsPositive(r):\r\n",
        "    return True if r[1] else False\r\n",
        "def IsNegative(r):\r\n",
        "    return True if not r[1] else False\r\n",
        "\r\n",
        "username_list = usernames_df.values.tolist()\r\n",
        "hostnames_list = hostnames_df.values.tolist()\r\n",
        "filenames_list = filenames_df.values.tolist()\r\n",
        "\r\n",
        "positive_dataset = list(filter(IsPositive, username_list+hostnames_list+filenames_list))\r\n",
        "negative_dataset = list(filter(IsNegative, username_list+hostnames_list+filenames_list))\r\n",
        "\r\n",
        "random.shuffle(positive_dataset)\r\n",
        "random.shuffle(negative_dataset)\r\n",
        "\r\n",
        "print(len(positive_dataset))\r\n",
        "print(positive_dataset[:10])\r\n",
        "print(len(negative_dataset))\r\n",
        "print(negative_dataset[:10])\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25839\n",
            "[['/reset.css', 1], ['RT SamsungMobile:  Boom! BTS_twt - We couldnt be more proud of your #GRAMMYs nomination! You guys are dynamite!  #GrammyNominatedB', 1], ['RT shenna_brook: being loved like a morgan wallen song &gt;', 1], ['/blog/geekery/puppet-nodeless-configuration..cs', 1], ['/projects/firefox-urledit..java', 1], ['/presentations/logstash-scale11x/plugin/zoom-js/zoom.js', 1], ['/reset.css', 1], ['/images/web/2009/banner.png', 1], ['RT OnActuate: How do you prioritise datacenter discovery to accelerate cloud migration? https://t.co/SElM7nALny #microsoft #onactuate #ms', 1], ['RT chrysallium: YEAHHHH CONGRATSSS Ohmmmmmmyyyyyyyyggghghhhhhhhgggggggggdhdhsjsixudbslsogbdsisgshdbxidjdbdidhdifjfiri #GRAMMYs #BTS #Gra', 1]]\n",
            "10137\n",
            "[['159232232246', 0], ['A seamless phone-to-PC experience, right in your hands. Get more out of your #GalaxyNote20 apps with Microsoft. https://t.co/8Mhtld366g', 0], ['Office 365 Roadmap | Microsoft Information Protection: Data-at-Rest Encryption for Microsoft 365 in DoD and GCC-High#UFO365Roadmap #Office365https://t.co/dJ3Mn5DpUD', 0], ['5CLAIR-MCKNIGHT', 0], ['ORAMCGUIREORAMCGUIREORAMCGUIRE', 0], ['Operation Azure? Oh dear. Something bad happened...', 0], ['I dont know how theyd do it but I think itd be better for the sport of baseball if the offseason moves as quick as the NBA. It would keep fans engaged, maybe attract some new ones, and make the offseason something to look forward to. Find a way to stimulate the market. #mlb', 0], ['InterestingIf you are a UK business looking for a CRM system go to Business Lowdown https://t.co/pxsvSubXkP for in-depth information &amp; guidance. #uk #business #startup #smallbiz #smallbusinesssupport #supportsmallbiz #crm #crmsoftware #cloud #remoteworkforce #smeuk #smb https://t.co/BBJ6lQ5hPU', 0], ['31 days until the 2021 NHL Regular Season should start. #gostars', 0], ['Guessing none of you wanna play Zombies with me ', 0]]\n"
          ]
        }
      ],
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876584515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the dataset into 1\r\n",
        "dataset = []\r\n",
        "l = len(negative_dataset) if len(negative_dataset) < len(positive_dataset) else len(positive_dataset)\r\n",
        "\r\n",
        "for i in range(0,l):\r\n",
        "    dataset.append(positive_dataset[i])\r\n",
        "    dataset.append(negative_dataset[i])\r\n",
        "print(dataset[:5])\r\n",
        "print(len(dataset))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['/reset.css', 1], ['159232232246', 0], ['RT SamsungMobile:  Boom! BTS_twt - We couldnt be more proud of your #GRAMMYs nomination! You guys are dynamite!  #GrammyNominatedB', 1], ['A seamless phone-to-PC experience, right in your hands. Get more out of your #GalaxyNote20 apps with Microsoft. https://t.co/8Mhtld366g', 0], ['RT shenna_brook: being loved like a morgan wallen song &gt;', 1]]\n",
            "20274\n"
          ]
        }
      ],
      "execution_count": 75,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876601771
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\r\n",
        "\r\n",
        "# Username specific features\r\n",
        "def LowerUnderscoreUpper(s):\r\n",
        "    l = len(s)\r\n",
        "\r\n",
        "    for i in range(0,l-2):\r\n",
        "        if s[i].islower() and s[i+1] == '_' and s[i+2].isupper():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasUnderscore(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for c in s:\r\n",
        "        if c == '_':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def LowerUpperLower(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for i in range(0, len(s)-2):\r\n",
        "        if s[i].islower() and s[i+1].isupper() and s[i+2].islower():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def MultipleLowerUpperLower(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    flag = False\r\n",
        "    for i in range(0, len(s)-2):\r\n",
        "        if s[i].islower() and s[i+1].isupper() and s[i+2].islower():\r\n",
        "            if flag:\r\n",
        "                return True\r\n",
        "            else:\r\n",
        "                flag = True\r\n",
        "    return False\r\n",
        "\r\n",
        "def ExactlyTwoUppercase(s):\r\n",
        "    count = 0\r\n",
        "\r\n",
        "    for c in s:\r\n",
        "        if c.isupper():\r\n",
        "            count+=1\r\n",
        "    if count ==2:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def AllLowerMoreThan(bound, s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    if len(s) < bound:\r\n",
        "        return False\r\n",
        "    for c in s:\r\n",
        "        if c.isupper():\r\n",
        "            return False\r\n",
        "    return True\r\n",
        "\r\n",
        "def AdjacentUppers(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    for i in range(0,len(s)-1):\r\n",
        "        if s[i].isupper() and s[i+1].isupper():\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def StartLetterEndNonLetter(s):\r\n",
        "    s = str(s)\r\n",
        "\r\n",
        "    if s[0].isalpha() and not s[-1].isalpha():\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "\r\n",
        "# Hostname specific features\r\n",
        "def LengthGTLT(gt, ls, s):\r\n",
        "    l = len(str(s))\r\n",
        "    if l >= gt and l <= ls:\r\n",
        "        return True\r\n",
        "    else:\r\n",
        "        return False\r\n",
        "\r\n",
        "def IllegalHostnameChars(s):\r\n",
        "    s = str(s)\r\n",
        "    illegal_chars = [\".\", \"\\\", \"\"/\", \"*\", \"?\", \"\\\"\", \"<\", \">\", \"|\", \",\", \"~\", \":\", \"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"'\", \"(\", \")\", \"{\", \"}\", \" \"]\r\n",
        "    for c in s:\r\n",
        "        if c in illegal_chars:\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def AlphaOrDigit(s):\r\n",
        "    s = str(s)\r\n",
        "    if s.isalpha() or s.isdigit():\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HostIllegalEnding(s):\r\n",
        "    s = str(s)\r\n",
        "    if s[-1] == '-' or s[-1] == '.':\r\n",
        "        return True\r\n",
        "    return False\r\n",
        "\r\n",
        "# Filename specific features\r\n",
        "\r\n",
        "def ContainsPeriod(s):\r\n",
        "    s = str(s)\r\n",
        "    for c in s:\r\n",
        "        if c == '.':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def IsUrl(s):\r\n",
        "    s = str(s)\r\n",
        "    l = len(s)\r\n",
        "    if l > 3:\r\n",
        "        if s[0:4] == \"http\":\r\n",
        "            return True\r\n",
        "    if l > 4:\r\n",
        "        if s[0:5] == \"https\":\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasSlash(s):\r\n",
        "    s = str(s)\r\n",
        "    for c in s:\r\n",
        "        if c == '/' or c == '\\\\':\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasMultipleSlash(s):\r\n",
        "    s = str(s)\r\n",
        "    slashes = ['/','\\\\']\r\n",
        "    flag = False\r\n",
        "    for c in s:\r\n",
        "        if not flag and c in slashes:\r\n",
        "            flag = True\r\n",
        "        elif flag and c in slashes:\r\n",
        "            return True\r\n",
        "    return False\r\n",
        "\r\n",
        "def HasPossibleExtension(s):\r\n",
        "    s = str(s)\r\n",
        "    for i in range(0,len(s)):\r\n",
        "        if s[i] == '.':\r\n",
        "            x = s[i:-1]\r\n",
        "            if len(x) >= 2 and len(x) <= 4:\r\n",
        "                return True\r\n",
        "    return False\r\n"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606866041344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features and labels\r\n",
        "feature_list = []\r\n",
        "labels = []\r\n",
        " \r\n",
        "tk = WhitespaceTokenizer() \r\n",
        "\r\n",
        "for dp in dataset:\r\n",
        "    d = dp[0]\r\n",
        "    label = dp[1]\r\n",
        "    tokens = tk.tokenize(d)\r\n",
        "    tokens = list(filter(lambda x: not IsUrl(x), tokens))\r\n",
        "    dp_list = []\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LowerUnderscoreUpper(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasUnderscore(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LowerUpperLower(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: MultipleLowerUpperLower(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: ExactlyTwoUppercase(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AllLowerMoreThan(10,x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AdjacentUppers(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: StartLetterEndNonLetter(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: LengthGTLT(1, 15, x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: IllegalHostnameChars(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: AlphaOrDigit(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HostIllegalEnding(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: ContainsPeriod(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasSlash(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasMultipleSlash(x), tokens)) else dp_list.append(False)\r\n",
        "    dp_list.append(True) if True in list(map(lambda x: HasPossibleExtension(x), tokens)) else dp_list.append(False)\r\n",
        "    feature_list.append(dp_list)\r\n",
        "    labels.append(label)\r\n"
      ],
      "outputs": [],
      "execution_count": 76,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876610847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN MACHINE LEARNING MODELS\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import recall_score"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606875531218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcAccuracy(target, predictions):\r\n",
        "    total = len(predictions)\r\n",
        "    correct = 0\r\n",
        "    for i in range(len(predictions)):\r\n",
        "        if target[i] == predictions[i]:\r\n",
        "            correct += 1\r\n",
        "        accuracy = float(correct) / float(total)\r\n",
        "    return accuracy\r\n",
        "\r\n",
        "def FalsePositives(x_test, y_test, pred):\r\n",
        "    false_positives = []\r\n",
        "    for i in range(0, len(x_test)):\r\n",
        "        if y_test[i] == 0 and pred[i] == 1:\r\n",
        "            false_positives.append(x_test[i])\r\n",
        "    return false_positives\r\n",
        "\r\n",
        "def FalseNegatives(x_test, y_test, pred):\r\n",
        "    false_negatives = []\r\n",
        "    for i in range(0,len(x_test)):\r\n",
        "        if y_test[i] == 1 and pred[i] == 0:\r\n",
        "            false_negatives.append(x_test[i])\r\n",
        "    return false_negatives\r\n",
        "\r\n",
        "def PrintResults(classifier, acc, recall, precision):\r\n",
        "    print(classifier + \" Classifier\")\r\n",
        "    print(\"Accuracy= \", acc)\r\n",
        "    print(\"Precision= \", precision)\r\n",
        "    print(\"Recall= \", recall)"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606875643243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = feature_list # all the features\r\n",
        "y = labels     # labels, 1 or 0\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\r\n",
        "print(len(X))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20274\n"
          ]
        }
      ],
      "execution_count": 77,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876616062
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DECISION TREE CLASSIFIER\r\n",
        "dt = DecisionTreeClassifier().fit(X_train, y_train)\r\n",
        "pred = dt.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Decision Tree\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy=  0.92063966522194\n",
            "Precision=  0.9199160167966407\n",
            "Recall=  0.9207445211648154\n",
            "\n",
            "FP-> 267 \n",
            "FN-> 264\n"
          ]
        }
      ],
      "execution_count": 78,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876619850
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN CLASSIFIER\r\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\r\n",
        "knn.fit(X_train, y_train)\r\n",
        "pred = knn.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"KNN\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier\n",
            "Accuracy=  0.9073382155133761\n",
            "Precision=  0.8932404989846243\n",
            "Recall=  0.924347042930051\n",
            "\n",
            "FP-> 368 \n",
            "FN-> 252\n"
          ]
        }
      ],
      "execution_count": 79,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876625830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGISTIC REGRESSION CLASSIFER\r\n",
        "lr = LogisticRegression(random_state=0)\r\n",
        "lr.fit(X_train, y_train)\r\n",
        "pred = lr.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Logistic Regression\", acc, recall, precision)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier\n",
            "Accuracy=  0.8756538633985951\n",
            "Precision=  0.8950363578880809\n",
            "Recall=  0.8498949264485139\n"
          ]
        }
      ],
      "execution_count": 80,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876629785
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FORREST\r\n",
        "rfm = RandomForestClassifier().fit(X_train, y_train)\r\n",
        "pred = rfm.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Random Forrest\", acc, recall, precision)\r\n",
        "\r\n",
        "false_negatives = FalseNegatives(X_test, y_test, pred)\r\n",
        "false_positives = FalsePositives(X_test, y_test, pred)\r\n",
        "\r\n",
        "print(f\"\\nFP-> {len(false_positives)} \\nFN-> {len(false_negatives)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forrest Classifier\n",
            "Accuracy=  0.923927664026304\n",
            "Precision=  0.9219497607655502\n",
            "Recall=  0.925547883518463\n",
            "\n",
            "FP-> 261 \n",
            "FN-> 248\n"
          ]
        }
      ],
      "execution_count": 81,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876632930
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NAIVE BAYS\r\n",
        "nb = GaussianNB().fit(X_train, y_train)\r\n",
        "pred = nb.predict(X_test)\r\n",
        "acc = calcAccuracy(y_test, pred)\r\n",
        "recall = recall_score(y_test, pred)\r\n",
        "precision = precision_score(y_test, pred)\r\n",
        "PrintResults(\"Naive Bays\", acc, recall, precision)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bays Classifier\n",
            "Accuracy=  0.7188761022268719\n",
            "Precision=  0.838468720821662\n",
            "Recall=  0.5391774241969378\n"
          ]
        }
      ],
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606876636084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try/Catch for recognizing if input is json or not\r\n",
        "\r\n",
        "#data_dict = list(map(lambda x : ast.literal_eval(x), data))\r\n",
        "for x in dataset[:5]:\r\n",
        "    print(x)\r\n",
        "\r\n",
        "for y in dataset:\r\n",
        "    x = None\r\n",
        "    try:\r\n",
        "        x = ast.literal_eval(y[0])\r\n",
        "        #print(f\"It didn't break! {x}\")\r\n",
        "    except (ValueError, SyntaxError):\r\n",
        "        z = True\r\n",
        "        #print(f\"It broke:( {y}\") \r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#ReTweetThis for #OurMischief #BBlogRT SGH_RTs GFXCoach FearRTs ShoutGamers Demented_RTs Mighty_RTs DynoRTs NightRetweets WitWGARA posted: https://t.co/oAcPcjMyvAWatch Ninja now streaming VALORANTat https://t.co/QghgQSwvrL- #ThankYou for being #OurMischief! Wit', 1]\n",
            "['TRUDYDELEON-', 0]\n",
            "['groucho-eu', 1]\n",
            "['7JERRY-NELSON', 0]\n",
            "['RT tkasasagi: My Kuzushiji recognition mobile app using Tensorflow and Flutter project got awarded research grant from Japan Science and T', 1]\n"
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606874741766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = WhitespaceTokenizer() \r\n",
        "t1 = \"Hello\"\r\n",
        "token = tk.tokenize(t1)\r\n",
        "print(token)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello']\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1606874783950
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}